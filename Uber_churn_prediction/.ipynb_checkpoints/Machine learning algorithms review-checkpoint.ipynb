{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A memo and review of the popular ML algorithms\n",
    "- First we will try to answer generally why we need a model and how do we train, interpret, evaluate, validate and choose between different models based on the pros and cons of each model\n",
    "- Then we will have detailed discussions of different models\n",
    "- Linear models: Linear regression and logistic regression\n",
    "- Tree-based models: Basic decision tree and ensembled trees such as random forest and gradient boosted decison tree\n",
    "- SVM\n",
    "- Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model represents the relationship between variables. We want to build the relationship between the features and response variables, while making some simplifying assuptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why we model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are mainly two purposes: prediction and inference.\n",
    "- For prediction purpose, we want to predict the value of response variable given a set of features. And we care more about getting the right answer over knowing the relationship between features and respons. For e.g, predicting stock prices.\n",
    "- For inference purpose, in contrast, we care more about the relationship between features and response. For e.g, finding out the most important features in predicting house prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore there is tradeoff between these two purposes. Linear regression is great for inference, the coefficient tells us by how much the response will change with one unit change of the feature. While a Gaussian kernal SVM could result in higher accurary, but it is hard to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the right model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally there are two steps in achieving a good model. Building the model given a set of inputs and choosing between the models. The pool of metrics used for training and choosing model are the same for each model. The key difference is that when we train a model, we only use one metric score and when we choose a model, we use any number of metrics.\n",
    "- Building the model: Each type of model has its own algorithm/equation when fitting a fixed set of inputs. The result is a model. The training process tries to minimize the target metric in order to optimize the model. This target metric is referred as loss. For regression problems we ofen use residual sum of squares(RSS) as the loss and for classification we use cross entropy.\n",
    "- Choosing the model: When choosing a model, we need to consider like model performance, interprebility, scalabibilty and so on since there are trade-offs on these among different models. It is often determined by the project need and knowledge and experience of the data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a supervised model, we want to know how the model performs by validating it on a different data set. Therefore we often devide the available data set to train and test sets, with ratio 80:20. \n",
    "- If the model performs much worse on the test set we will say there is overfitting. And in order to solve this, we could get more data, use regularization, reduce the features, decrease the flexibility of the model and so on.\n",
    "- If the model perform about the same on training and test data sets but are both very bad we will say there exists bias in the model. We could engineer more features, increase the flexibility of the model ... to solve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often use the k-fold cross validation to choose some hyperparameters. It works as follows:\n",
    "- We devide the training data set into k groups. Each time we train a model of (k - 1) groups of data and used the model to predict observations in the left group and return a score.\n",
    "- We repeat this step k times for each group of data, and average the scores and use this score as the standard to choose the parameters of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics of models:\n",
    "- Dimension safe: How well will the model perfrom if we have a lot of features? If the number of features(p) is greater than the number of observations in data(n)?\n",
    "- Training speed: How long does it take to train the model?\n",
    "- Prediction speed: Once we have the trained model, how long does it take to make predictions?\n",
    "- Interpretability: Especially important when our purpose is to make inference. Can we determing the most important features and their direct cause on the response?\n",
    "- Communication: How do we explain the model in 2 sentences to non-techical colleagues?\n",
    "- Visulization: How do we present the model visually?\n",
    "- Evaluation: What metrics can we use to score the models in order to choose the best model?\n",
    "- Nonlinearity: How does this model react to nonlinear data?\n",
    "- Multicoliearity: Could the model take multilinearity well?\n",
    "- Outliers: Is the model robust to outliers?\n",
    "- Overfitting: Does this model tend to overfit?\n",
    "- Hyperparameters: What parameters can we tune in order to achieve a better score for this model?\n",
    "- Online: Can the model be easily updated with new data(without fitting using previous fitted data)?\n",
    "- Unique attributes for each model\n",
    "- Special use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other general notes\n",
    "More data usually produces better model. Better features usually beat a better model. Therefore data collection and feature engineering typically trump model selection. Keep this in mind when tackling a new problem.\n",
    "\n",
    "The real life data are usually messy: the inputs tend to be mixtures of quantitative, binary and categorical values, the latter often with mamy levels. There are also generally many missing values. Distributions of numerical predictors and response are often long-tailed and highly skewed.\n",
    "\n",
    "Usually only a small fraction of the large number of predictors that have been included in the analysis are actually relevant to the response.\n",
    "\n",
    "Furthermore, when doing model selection, trying out several different kinds of models is one of the best way to determine which model to use, and you might ultimated find an ensemble works the best.\n",
    "\n",
    "Things like interpretability, speed, simplicity will guide your choice of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume simple linear relationship between the predictors and the response variables.\n",
    "$ Y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_px_p + \\epsilon$, where $\\epsilon$ is random error. When fitting the model, we choose then parameters which minimizes the residual sum of squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions of linear regression\n",
    "- There is linear relationship between predictors and response variables\n",
    "- The distribution of X is arbitraty, and the observations are indepent of each other\n",
    "- The random error is independent for each observation, the expected value is 0, and the variance is constant\n",
    "- Gaussian noise assumption: $\\epsilon \\sim N(0, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some notes on the assumptions\n",
    "- True relationship between Y and X might not be linear, but according to Taylor expansion, it is a good approximationa and it is better than nothing\n",
    "- There is no assumption about the distribution of X, Y or the disjoint distribution of X and Y\n",
    "- No assumption about causality that X causes Y\n",
    "- No assumption that X is more precise, Y is more accurate\n",
    "- It is not always normal distributed error term, but a good approximation according to CLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
